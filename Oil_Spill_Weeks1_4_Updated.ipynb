{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230d4bf1",
   "metadata": {},
   "source": [
    "# ðŸš€ Oil Spill Detection Internship Project\n",
    "### Combined Weeks 1â€“4 Notebook (Updated with Real Training)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d02dfeb",
   "metadata": {},
   "source": [
    "## âœ… Week 1: Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81305e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip -q \"/content/drive/MyDrive/Oil_Spill_Project/dataset.zip\" -d /content/oil_spill_data\n",
    "!ls /content/oil_spill_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8448c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "base_dir = \"/content/oil_spill_data\"\n",
    "\n",
    "print(\"Top-level folders:\", os.listdir(base_dir))\n",
    "print(\"\\nTrain folder structure:\", os.listdir(os.path.join(base_dir, \"train\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75877a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_files(path):\n",
    "    total = 0\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        total += len([f for f in files if not f.startswith('.')])\n",
    "    return total\n",
    "\n",
    "print(\"Train Images:\", count_files(os.path.join(base_dir, \"train/images\")))\n",
    "print(\"Train Masks :\", count_files(os.path.join(base_dir, \"train/masks\")))\n",
    "print(\"Val Images  :\", count_files(os.path.join(base_dir, \"val/images\")))\n",
    "print(\"Val Masks   :\", count_files(os.path.join(base_dir, \"val/masks\")))\n",
    "print(\"Test Images :\", count_files(os.path.join(base_dir, \"test/images\")))\n",
    "print(\"Test Masks  :\", count_files(os.path.join(base_dir, \"test/masks\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff9cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2, matplotlib.pyplot as plt, random\n",
    "\n",
    "img_dir = os.path.join(base_dir, \"train/images\")\n",
    "mask_dir = os.path.join(base_dir, \"train/masks\")\n",
    "\n",
    "random_img = random.choice(os.listdir(img_dir))\n",
    "\n",
    "img = cv2.imread(os.path.join(img_dir, random_img))\n",
    "mask = cv2.imread(os.path.join(mask_dir, random_img.replace(\".jpg\", \".png\")), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1); plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.title(\"Image\")\n",
    "plt.subplot(1,2,2); plt.imshow(mask, cmap=\"gray\"); plt.title(\"Mask\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243786d",
   "metadata": {},
   "source": [
    "## âœ… Week 2: Data Exploration & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def preprocess_image(image, size=(256,256)):\n",
    "    image = cv2.resize(image, size)\n",
    "    image = image / 255.0\n",
    "    return image\n",
    "\n",
    "def preprocess_mask(mask, size=(256,256)):\n",
    "    mask = cv2.resize(mask, size, interpolation=cv2.INTER_NEAREST)\n",
    "    mask = mask / 255.0\n",
    "    return mask\n",
    "\n",
    "def speckle_reduction(image):\n",
    "    return cv2.medianBlur(image, 3)\n",
    "\n",
    "img_pre = preprocess_image(img)\n",
    "mask_pre = preprocess_mask(mask)\n",
    "img_denoised = speckle_reduction((img_pre*255).astype(np.uint8))\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1); plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)); plt.title(\"Original\")\n",
    "plt.subplot(1,3,2); plt.imshow(img_pre); plt.title(\"Resized + Normalized\")\n",
    "plt.subplot(1,3,3); plt.imshow(img_denoised, cmap=\"gray\"); plt.title(\"After Noise Reduction\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8,1.2]\n",
    ")\n",
    "\n",
    "img_resized = cv2.resize(img, (256,256))\n",
    "img_resized = np.expand_dims(img_resized, 0)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for i, batch in enumerate(datagen.flow(img_resized, batch_size=1)):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(batch[0].astype(\"uint8\"))\n",
    "    if i == 5: break\n",
    "plt.suptitle(\"Augmented Samples\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72edd5b",
   "metadata": {},
   "source": [
    "## âœ… Week 3: Model Development (U-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet_model(input_size=(256,256,3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    bn = layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
    "    bn = layers.Conv2D(256, 3, activation='relu', padding='same')(bn)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = layers.Conv2DTranspose(128, (2,2), strides=(2,2), padding='same')(bn)\n",
    "    u1 = layers.concatenate([u1, c2])\n",
    "    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(u1)\n",
    "    c3 = layers.Conv2D(128, 3, activation='relu', padding='same')(c3)\n",
    "\n",
    "    u2 = layers.Conv2DTranspose(64, (2,2), strides=(2,2), padding='same')(c3)\n",
    "    u2 = layers.concatenate([u2, c1])\n",
    "    c4 = layers.Conv2D(64, 3, activation='relu', padding='same')(u2)\n",
    "    c4 = layers.Conv2D(64, 3, activation='relu', padding='same')(c4)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1,1), activation='sigmoid')(c4)\n",
    "\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "model = unet_model()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f9ae5",
   "metadata": {},
   "source": [
    "## âœ… Week 4: Training & Validation (Updated with Real Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c75cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "IMG_SIZE = 256\n",
    "\n",
    "def load_images_and_masks(img_dir, mask_dir, size=(IMG_SIZE, IMG_SIZE)):\n",
    "    images, masks = [], []\n",
    "    img_files = glob.glob(os.path.join(img_dir, \"*.jpg\"))\n",
    "    \n",
    "    for img_path in img_files:\n",
    "        mask_path = os.path.join(mask_dir, os.path.basename(img_path).replace(\".jpg\", \".png\"))\n",
    "        if not os.path.exists(mask_path):\n",
    "            continue\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, size) / 255.0\n",
    "        \n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, size, interpolation=cv2.INTER_NEAREST)\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "        \n",
    "        images.append(img)\n",
    "        masks.append(np.expand_dims(mask, axis=-1))\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "X_train, y_train = load_images_and_masks(os.path.join(base_dir, \"train/images\"),\n",
    "                                         os.path.join(base_dir, \"train/masks\"))\n",
    "X_val, y_val = load_images_and_masks(os.path.join(base_dir, \"val/images\"),\n",
    "                                     os.path.join(base_dir, \"val/masks\"))\n",
    "\n",
    "print(\"Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"Val set  :\", X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605eca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee17c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b44232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds = model.predict(X_val[:3])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,3*i+1); plt.imshow(X_val[i]); plt.title(\"Image\")\n",
    "    plt.subplot(3,3,3*i+2); plt.imshow(y_val[i].squeeze(), cmap=\"gray\"); plt.title(\"True Mask\")\n",
    "    plt.subplot(3,3,3*i+3); plt.imshow((preds[i].squeeze()>0.5).astype(\"uint8\"), cmap=\"gray\"); plt.title(\"Predicted Mask\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19856bef",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Summary\n",
    "- **Week 1:** Dataset collected and verified.\n",
    "- **Week 2:** Data preprocessed + augmented.\n",
    "- **Week 3:** U-Net model built and compiled.\n",
    "- **Week 4:** Model trained on **real dataset**, validated, and predictions visualized.\n",
    "---\n",
    "âœ… Data and model are now ready for **Week 5â€“6: Evaluation & Deployment**."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}